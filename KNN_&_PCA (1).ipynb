{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is KNN and how does it work?\n",
        "\n",
        "Answer:\n",
        "K-Nearest Neighbors (KNN) is a simple, non-parametric machine learning algorithm used for classification and regression.\n",
        "\n",
        "How it works in Classification:\n",
        "\n",
        "A new data point is given.\n",
        "\n",
        "Find its K nearest neighbors using a distance metric (Euclidean, Manhattan etc.)\n",
        "\n",
        "Check which class is most common among these neighbors.\n",
        "\n",
        "Assign that class to the new point.\n",
        "\n",
        "How it works in Regression:\n",
        "\n",
        "Find K nearest neighbors.\n",
        "\n",
        "Take the average (or weighted average) of their numerical target values.\n",
        "\n",
        "That becomes the prediction."
      ],
      "metadata": {
        "id": "8WqUkOuP4tMA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: What is the Curse of Dimensionality and how does it affect KNN?\n",
        "\n",
        "Answer:\n",
        "The Curse of Dimensionality refers to problems that occur when data has a very large number of features.\n",
        "\n",
        "How it affects KNN:\n",
        "\n",
        "Distance between points becomes less meaningful in high dimensions.\n",
        "\n",
        "All points appear almost equally far, making nearest neighbors unreliable.\n",
        "\n",
        "KNN becomes slow because it must compute distances in many dimensions.\n",
        "\n",
        "Model accuracy decreases due to sparse data."
      ],
      "metadata": {
        "id": "C10mO8R44u3u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: What is PCA? How is it different from Feature Selection?\n",
        "\n",
        "Answer:\n",
        "PCA (Principal Component Analysis) is a dimensionality reduction technique that transforms original features into new uncorrelated features called principal components.\n",
        "\n",
        "PCA vs Feature Selection\n",
        "Feature Selection\tPCA\n",
        "Removes some features\tCreates new transformed features\n",
        "Keeps original meaning\tComponents lose original interpretation\n",
        "Selects best subset\tCreates linear combinations"
      ],
      "metadata": {
        "id": "iIFuv3f94x5o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: What are Eigenvalues and Eigenvectors in PCA? Why important?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Eigenvectors → directions of maximum variance in data (principal components).\n",
        "\n",
        "Eigenvalues → amount of variance captured by each eigenvector.\n",
        "\n",
        "Importance:\n",
        "\n",
        "Larger eigenvalue → more important component\n",
        "\n",
        "Helps decide how many components to keep\n",
        "\n",
        "Determines how PCA compresses the data"
      ],
      "metadata": {
        "id": "RYZQF7I540o2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: How do KNN and PCA complement each other?\n",
        "\n",
        "Answer:\n",
        "\n",
        "KNN performs poorly in high dimensions.\n",
        "\n",
        "PCA reduces dimensions, removes noise, and improves KNN performance.\n",
        "\n",
        "PCA speeds up KNN and avoids the curse of dimensionality.\n",
        "\n",
        "Together they create a stable machine learning pipeline."
      ],
      "metadata": {
        "id": "Am_vGKuz42nv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 6: KNN with & without Scaling on Wine Dataset\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_wine()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Without Scaling\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "pred1 = knn.predict(X_test)\n",
        "acc_without = accuracy_score(y_test, pred1)\n",
        "\n",
        "# With Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "knn2 = KNeighborsClassifier(n_neighbors=5)\n",
        "knn2.fit(X_train_scaled, y_train)\n",
        "pred2 = knn2.predict(X_test_scaled)\n",
        "acc_with = accuracy_score(y_test, pred2)\n",
        "\n",
        "print(\"Accuracy without scaling:\", acc_without)\n",
        "print(\"Accuracy with scaling:\", acc_with)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shL9GX4W45v-",
        "outputId": "914f94d2-992f-424d-896a-0bd84bcb8459"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 0.7222222222222222\n",
            "Accuracy with scaling: 0.9444444444444444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 7: PCA Explained Variance Ratio\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "\n",
        "pca = PCA()\n",
        "pca.fit(X)\n",
        "\n",
        "print(pca.explained_variance_ratio_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTtqXDBz5EWF",
        "outputId": "5a6102d9-4b50-467f-8bc6-0510ccddedbf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9.98091230e-01 1.73591562e-03 9.49589576e-05 5.02173562e-05\n",
            " 1.23636847e-05 8.46213034e-06 2.80681456e-06 1.52308053e-06\n",
            " 1.12783044e-06 7.21415811e-07 3.78060267e-07 2.12013755e-07\n",
            " 8.25392788e-08]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 8: KNN on PCA (2 Components)\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X)\n",
        "\n",
        "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
        "\n",
        "knn_p = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_p.fit(X_train_p, y_train_p)\n",
        "pred_p = knn_p.predict(X_test_p)\n",
        "\n",
        "acc_pca = accuracy_score(y_test_p, pred_p)\n",
        "\n",
        "print(\"Accuracy with PCA (2 components):\", acc_pca)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaTb_wlr5J6G",
        "outputId": "f6a9f662-53c8-429b-c993-5ca6e3f3395b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with PCA (2 components): 0.7222222222222222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 9: KNN with Euclidean vs Manhattan Distance\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Euclidean\n",
        "knn_e = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
        "knn_e.fit(X_train_s, y_train_s)\n",
        "acc_e = accuracy_score(y_test_s, knn_e.predict(X_test_s))\n",
        "\n",
        "# Manhattan\n",
        "knn_m = KNeighborsClassifier(n_neighbors=5, metric='manhattan')\n",
        "knn_m.fit(X_train_s, y_train_s)\n",
        "acc_m = accuracy_score(y_test_s, knn_m.predict(X_test_s))\n",
        "\n",
        "print(\"Euclidean Accuracy:\", acc_e)\n",
        "print(\"Manhattan Accuracy:\", acc_m)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2t3K1IKK5Nql",
        "outputId": "42c06dd5-1044-4020-d13a-34a040babcb5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Euclidean Accuracy: 0.9444444444444444\n",
            "Manhattan Accuracy: 0.9444444444444444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: Cancer Gene Expression Dataset – PCA + KNN Pipeline\n",
        "\n",
        "Answer:\n",
        "\n",
        "1. Using PCA for Dimensionality Reduction\n",
        "\n",
        "Gene datasets have thousands of features.\n",
        "\n",
        "PCA reduces noise and correlation.\n",
        "\n",
        "Retains maximum biological information.\n",
        "\n",
        "2. Selecting Number of Components\n",
        "\n",
        "Plot cumulative explained variance.\n",
        "\n",
        "Choose components covering 90–95% variance.\n",
        "\n",
        "3. KNN After PCA\n",
        "\n",
        "Use reduced PCA output as input to KNN.\n",
        "\n",
        "KNN performs better due to fewer noisy dimensions.\n",
        "\n",
        "4. Model Evaluation\n",
        "\n",
        "Use train-test split / cross-validation\n",
        "\n",
        "Metrics: accuracy, F1-score, confusion matrix\n",
        "\n",
        "5. Why This Pipeline Is Robust\n",
        "\n",
        "Reduces overfitting (common in biomedical datasets)\n",
        "\n",
        "Improves model speed and stability\n",
        "\n",
        "Works well even with small sample sizes\n",
        "\n",
        "Easy to interpret and explain to doctors/stakeholders"
      ],
      "metadata": {
        "id": "S2HON65i5VLt"
      }
    }
  ]
}